{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'timestamp',\n",
       "  'product_id',\n",
       "  'product_department',\n",
       "  'product_category',\n",
       "  'card_id',\n",
       "  'user_id',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'amount',\n",
       "  'isfraud'],\n",
       " 32369524)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_v2.csv')\n",
    "columns = list(train_data)\n",
    "N_original, M_original = train_data.shape\n",
    "columns, N_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "* With trees, normalizing features is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from include.DatetimeFromTimestamp import DatetimeFromTimestamp\n",
    "#from include.HourOfDay import HourOfDay\n",
    "#from include.DataFrameDropper import DataFrameDropper\n",
    "#from include.DataFrameSelector import DataFrameSelector\n",
    "#from include.FilterNMostCommon import FilterNMostCommon\n",
    "#from include.UserEvaluator import UserEvaluator\n",
    "from include.ConcatEncoder import ConcatEncoder\n",
    "#from sklearn.impute import SimpleImputer\n",
    "from include.ImputedColumn import ImputedColumn\n",
    "\n",
    "#columns_to_drop = ['id', 'timestamp', 'product_id', 'product_department', 'product_category', 'card_id', 'user_id']\n",
    "columns_to_use = ['C15_C16', 'C18_C17', 'C19', 'C20', 'C21', 'amount', 'cat_dep_id', 'card_user','-1s']\n",
    "mrf_prod = 1e-5\n",
    "mrf_card = 1e-5\n",
    "mrf_C = 5e-4\n",
    "#the hot encoded attributes are also used\n",
    "pipeline_normal = Pipeline([\n",
    "    #('hour_creator', HourOfDay()),\n",
    "    #('datetime_creator', DatetimeFromTimestamp()),\n",
    "    #('user_evaluator', UserEvaluator()),\n",
    "    ('imputed_column', ImputedColumn(missing_value=-1, target_column='C20', new_column='-1s')),\n",
    "    #('C20_imputer', SimpleImputer(missing_values=-1, strategy='constant', fill_value=10010)), #10010 because it is value that has a close probability of fraud from -1\n",
    "    ('concat_encoder_product', ConcatEncoder(['product_category', 'product_department', 'product_id'], attr_name='cat_dep_id', min_rel_freq=mrf_prod)),\n",
    "    ('concat_encoder_card', ConcatEncoder(['card_id', 'user_id'], attr_name='card_user', min_rel_freq=mrf_card)),\n",
    "    ('concat_encoder_C15_C16', ConcatEncoder(['C15', 'C16'], attr_name='C15_C16', min_rel_freq=mrf_C)),\n",
    "    ('concat_encoder_C18_C17', ConcatEncoder(['C18', 'C17'], attr_name='C18_C17', min_rel_freq=mrf_C)),\n",
    "    ('encoder_C19', ConcatEncoder(['C19'], attr_name='C19', min_rel_freq=mrf_C)),\n",
    "    ('encoder_C20', ConcatEncoder(['C20'], attr_name='C20', min_rel_freq=mrf_C)),\n",
    "    ('encoder_C21', ConcatEncoder(['C21'], attr_name='C21', min_rel_freq=mrf_C)),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=columns_to_use)),\n",
    "])\n",
    "\n",
    "#pipeline_1hot = Pipeline([\n",
    "    #('dataframe_selector', DataFrameSelector(['product_category'])),\n",
    "    #('filter_n_most_common', FilterNMostCommon(N=5, attribute_name='product_category', minRelFreq=0.05)),\n",
    "    #('1hot_encoder', OneHotEncoder(sparse = False))\n",
    "#])\n",
    "\n",
    "#pipeline_full = FeatureUnion(transformer_list=[\n",
    "    #('pipeline_normal', pipeline_normal),\n",
    "    #('pipeline_1hot', pipeline_1hot),\n",
    "#])\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "* Normally I would use random sampling, stratified by an attribute of major relevance, however, in this case the test data that was given follows the train data in time. Therefore, in order to do local testing my first guess would be that it is better to remake that scenario and sample the data by simply splitting it sorted as it is, by time.\n",
    "* Cross validation is not necessary given that we have a test set big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000000, 15), (6000000,), (6000000, 15), (6000000,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_by = 2\n",
    "N_train = 6000000\n",
    "N_test = 6000000\n",
    "\n",
    "start_at = N_original - N_train - N_test\n",
    "split_at = start_at + N_train\n",
    "\n",
    "train_X = pd.DataFrame(train_data.iloc[start_at:split_at,:-1])\n",
    "train_Y = train_data.iloc[start_at:split_at,-1]\n",
    "test_X = pd.DataFrame(train_data.iloc[split_at:,:-1])\n",
    "test_Y = train_data.iloc[split_at:,-1]\n",
    "\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000000, 9), (6000000, 9))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline_normal.fit(train_data, train_data['isfraud'])\n",
    "train_X_treated = pipeline_normal.transform(train_X)\n",
    "test_X_treated = pipeline_normal.transform(test_X)\n",
    "\n",
    "train_X_treated.shape, test_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929880743149611"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "crit='gini'\n",
    "h=16\n",
    "leaf=1/(4**4)\n",
    "split=1/(4**9)\n",
    "model = current_model(random_state=random_seed, criterion=crit, max_depth=h, min_samples_leaf=leaf, min_samples_split=split)\n",
    "model.fit(train_X_treated, train_Y)\n",
    "test_pred_prob = model.predict_proba(test_X_treated)[:,1]\n",
    "\n",
    "roc_auc_score(test_Y, test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit\n",
    "1. 0.6654 - 1 hot encoding of `product_category`\n",
    "2. 0.6264 - `hour` actualy decreases score. It will be removed for now, however it might be useful while combined with other attributes.\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "7. A lot of attempts which didn't increase the score with two features I created: `daily_transactions_ratio` and `daily_amount_ratio`, which represented the ratio between the number of transactions/the amount made by that user/card on that day with the average daily number of transactions/amount from that specific user.\n",
    "8. 0.6594 - Decision tree with label encoding of product stuff\n",
    "9. 0.6760 - also with label encoding of card and user stuff\n",
    "10. 0.6849 - Com product min rel freq a 1e-5\n",
    "11. 0.72364 - Otimized tree with: `crit='gini', h=16, leaf=1/(4**4), split=1/(4**9)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32369524, 15), (32369524,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X = train_data.iloc[:,:-1]\n",
    "train_data_Y = train_data.iloc[:,-1]\n",
    "train_data_X.shape, train_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32369524, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_normal.fit(train_data, train_data['isfraud'])\n",
    "train_data_X_treated = pipeline_normal.transform(train_data_X)\n",
    "del train_data_X\n",
    "train_data_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_treated = pipeline_normal.transform(submit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.00390625,\n",
       "            min_samples_split=3.814697265625e-06,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit='gini'\n",
    "h=16\n",
    "leaf=1/(4**4)\n",
    "split=1/(4**9)\n",
    "model = current_model(random_state=random_seed, criterion=crit, max_depth=h, min_samples_leaf=leaf, min_samples_split=split)\n",
    "model.fit(train_data_X_treated, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(submit_data_treated)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isfraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32263877</td>\n",
       "      <td>0.019840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32263886</td>\n",
       "      <td>0.100284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32263890</td>\n",
       "      <td>0.306197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32263895</td>\n",
       "      <td>0.306197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32263896</td>\n",
       "      <td>0.065333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   isfraud\n",
       "0  32263877  0.019840\n",
       "1  32263886  0.100284\n",
       "2  32263890  0.306197\n",
       "3  32263895  0.306197\n",
       "4  32263896  0.065333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = submit_data['id']\n",
    "submission['isfraud'] = pred_prob\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = 'data/submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count: 301\n"
     ]
    }
   ],
   "source": [
    "print('Node count:', model.tree_.node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000000, 9), (8000000,), (8000000, 9), (8000000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = 8000000\n",
    "n_test =  8000000\n",
    "start_at=n_train+n_test\n",
    "train_X_opt = train_data_X_treated.iloc[-start_at:-n_test,:]\n",
    "train_Y_opt = train_data_Y[-start_at:-n_test]\n",
    "test_X_opt = train_data_X_treated.iloc[-n_test:,:]\n",
    "test_Y_opt = train_data_Y[-n_test:]\n",
    "train_X_opt.shape, train_Y_opt.shape, test_X_opt.shape, test_Y_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.52587890625e-05,\n",
       "  6.103515625e-05,\n",
       "  0.000244140625,\n",
       "  0.0009765625,\n",
       "  0.00390625,\n",
       "  0.015625,\n",
       "  0.0625],\n",
       " [3.814697265625e-06,\n",
       "  1.52587890625e-05,\n",
       "  6.103515625e-05,\n",
       "  0.000244140625,\n",
       "  0.0009765625,\n",
       "  0.00390625,\n",
       "  0.015625,\n",
       "  0.0625],\n",
       " [32, 16, 8],\n",
       " 3.814697265625e-06)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria=['gini','entropy']\n",
    "s1 = [1/(4**idx) for idx in range(8, 1, -1)]\n",
    "s2 = [1/(4**idx) for idx in range(9, 1, -1)]\n",
    "height = [2**idx for idx in range(5,2,-1)]\n",
    "s1, s2, height,1/(4**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 0.743 - gini; h=16; leaf=^4; split=^9\n",
    "2. 0.741 - entropy; h=16; leaf=^4; split=^9\n",
    "3. 0.743 - gini; h=16; leaf=^4; split=^10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430119254143245"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit='gini'\n",
    "h=16\n",
    "leaf=1/(4**4)\n",
    "split=1/(4**9)\n",
    "model = current_model(random_state=random_seed, criterion=crit, max_depth=h, min_samples_leaf=leaf, min_samples_split=split)\n",
    "model.fit(train_X_opt, train_Y_opt)\n",
    "test_pred_prob = model.predict_proba(test_X_opt)[:,1]\n",
    "\n",
    "score = roc_auc_score(test_Y_opt, test_pred_prob)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best_score=0\n",
    "\n",
    "for crit in criteria:\n",
    "    for split in s2:\n",
    "        for leaf in s1:\n",
    "            for h in height:\n",
    "                model = current_model(random_state=random_seed, criterion=crit, max_depth=h, min_samples_leaf=leaf, min_samples_split=split)\n",
    "                model.fit(train_X_opt, train_Y_opt)\n",
    "                test_pred_prob = model.predict_proba(test_X_opt)[:,1]\n",
    "\n",
    "                score = roc_auc_score(test_Y_opt, test_pred_prob)\n",
    "                if score > best_score:\n",
    "                    print('---------')\n",
    "                    print('New best score: ', score, ' with: ')\n",
    "                    best_crit = crit\n",
    "                    best_split = split\n",
    "                    best_leaf = leaf\n",
    "                    best_h = h\n",
    "                    print('---------')\n",
    "                    best_score = score\n",
    "                print(crit)\n",
    "                print(split)\n",
    "                print(leaf)\n",
    "                print(h, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch_the_fraudster3",
   "language": "python",
   "name": "catch_the_fraudster3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
