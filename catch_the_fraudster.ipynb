{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'timestamp',\n",
       "  'product_id',\n",
       "  'product_department',\n",
       "  'product_category',\n",
       "  'card_id',\n",
       "  'user_id',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'amount',\n",
       "  'isfraud'],\n",
       " 32369524)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_v2.csv')\n",
    "columns = list(train_data)\n",
    "N_original, M_original = train_data.shape\n",
    "columns, N_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "* With trees, normalizing features is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from include.DatetimeFromTimestamp import DatetimeFromTimestamp\n",
    "#from include.HourOfDay import HourOfDay\n",
    "#from include.DataFrameDropper import DataFrameDropper\n",
    "from include.DataFrameSelector import DataFrameSelector\n",
    "from include.FilterNMostCommon import FilterNMostCommon\n",
    "#from include.UserEvaluator import UserEvaluator\n",
    "from include.ConcatEncoder import ConcatEncoder\n",
    "\n",
    "#columns_to_drop = ['id', 'timestamp', 'product_id', 'product_department', 'product_category', 'card_id', 'user_id']\n",
    "columns_to_use = ['C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'amount', 'cat_dep_id', 'card_user']\n",
    "mrf_prod = 1e-5\n",
    "mrf_card = 1e-5\n",
    "#the hot encoded attributes are also used\n",
    "pipeline_normal = Pipeline([\n",
    "    #('hour_creator', HourOfDay()),\n",
    "    #('datetime_creator', DatetimeFromTimestamp()),\n",
    "    #('user_evaluator', UserEvaluator()),\n",
    "    ('concat_encoder_product', ConcatEncoder(['product_category', 'product_department', 'product_id'], attr_name='cat_dep_id', min_rel_freq=mrf_prod)),\n",
    "    ('concat_encoder_card', ConcatEncoder(['card_id', 'user_id'], attr_name='card_user', min_rel_freq=mrf_card)),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=columns_to_use)),\n",
    "])\n",
    "\n",
    "pipeline_1hot = Pipeline([\n",
    "    ('dataframe_selector', DataFrameSelector(['product_category'])),\n",
    "    ('filter_n_most_common', FilterNMostCommon(N=5, attribute_name='product_category', minRelFreq=0.05)),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "pipeline_full = FeatureUnion(transformer_list=[\n",
    "    ('pipeline_normal', pipeline_normal),\n",
    "    ('pipeline_1hot', pipeline_1hot),\n",
    "])\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "* Normally I would use random sampling, stratified by an attribute of major relevance, however, in this case the test data that was given follows the train data in time. Therefore, in order to do local testing my first guess would be that it is better to remake that scenario and sample the data by simply splitting it sorted as it is, by time.\n",
    "* Cross validation is not necessary given that we have a test set big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15), (1000000,), (6000000, 15), (6000000,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_by = 2\n",
    "N_train = 1000000\n",
    "N_test = 6000000\n",
    "\n",
    "start_at = N_original - N_train - N_test\n",
    "split_at = start_at + N_train\n",
    "\n",
    "train_X = pd.DataFrame(train_data.iloc[start_at:split_at,:-1])\n",
    "train_Y = train_data.iloc[start_at:split_at,-1]\n",
    "test_X = pd.DataFrame(train_data.iloc[split_at:,:-1])\n",
    "test_Y = train_data.iloc[split_at:,-1]\n",
    "\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 9), (6000000, 9))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_normal.fit(train_data, train_data['isfraud'])\n",
    "train_X_treated = pipeline_normal.transform(train_X)\n",
    "test_X_treated = pipeline_normal.transform(test_X)\n",
    "\n",
    "train_X_treated.shape, test_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6194719072846742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_X_treated, train_Y)\n",
    "test_pred_prob = model.predict_proba(test_X_treated)[:,1]\n",
    "\n",
    "roc_auc_score(test_Y, test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit\n",
    "1. 0.6654 - 1 hot encoding of `product_category`\n",
    "2. 0.6264 - `hour` actualy decreases score. It will be removed for now, however it might be useful while combined with other attributes.\n",
    "3. A lot of insuccessful attempts\n",
    "\n",
    "...\n",
    "\n",
    "7. with the ratios were made.\n",
    "8. 0.6594 - Decision tree with label encoding of product stuff\n",
    "9. 0.6760 - also with label encoding of card and user stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32369524, 15), (32369524,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X = train_data.iloc[:,:-1]\n",
    "train_data_Y = train_data.iloc[:,-1]\n",
    "train_data_X.shape, train_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32369524, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_normal.fit(train_data, train_data['isfraud'])\n",
    "train_data_X_treated = pipeline_normal.transform(train_data_X)\n",
    "del train_data_X\n",
    "train_data_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_treated = pipeline_normal.transform(submit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_data_X_treated, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(submit_data_treated)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = submit_data['id']\n",
    "submission['isfraud'] = pred_prob\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = 'data/submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Node count:', model.tree_.node_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch_the_fraudster3",
   "language": "python",
   "name": "catch_the_fraudster3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
