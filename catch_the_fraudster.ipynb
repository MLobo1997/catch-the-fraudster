{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'timestamp',\n",
       "  'product_id',\n",
       "  'product_department',\n",
       "  'product_category',\n",
       "  'card_id',\n",
       "  'user_id',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'amount',\n",
       "  'isfraud'],\n",
       " 32369524)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_v2.csv')\n",
    "columns = list(train_data)\n",
    "N_original, M_original = train_data.shape\n",
    "columns, N_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "* With trees, normalizing features is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from include.DatetimeFromTimestamp import DatetimeFromTimestamp\n",
    "#from include.HourOfDay import HourOfDay\n",
    "#from include.DataFrameDropper import DataFrameDropper\n",
    "from include.DataFrameSelector import DataFrameSelector\n",
    "from include.FilterNMostCommon import FilterNMostCommon\n",
    "from include.UserEvaluator import UserEvaluator\n",
    "\n",
    "#columns_to_drop = ['id', 'timestamp', 'product_id', 'product_department', 'product_category', 'card_id', 'user_id']\n",
    "columns_to_use = ['C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'amount'] #the hot encoded attributes are also used\n",
    "pipeline_normal = Pipeline([\n",
    "    #('hour_creator', HourOfDay()),\n",
    "    ('user_evaluator', UserEvaluator(column_names=list(train_data))),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=columns_to_use)),\n",
    "])\n",
    "\n",
    "pipeline_1hot = Pipeline([\n",
    "    ('dataframe_selector', DataFrameSelector(['product_category'])),\n",
    "    ('filter_n_most_common', FilterNMostCommon(N=5, attribute_name='product_category')),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "pipeline_full = FeatureUnion(transformer_list=[\n",
    "    ('pipeline_normal', pipeline_normal),\n",
    "    ('pipeline_1hot', pipeline_1hot),\n",
    "])\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "* Normally I would use random sampling, stratified by an attribute of major relevance, however, in this case the test data that was given follows the train data in time. Therefore, in order to do local testing my first guess would be that it is better to remake that scenario and sample the data by simply splitting it sorted as it is, by time.\n",
    "* Cross validation is not necessary given that we have a test set big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15), (1000000,), (6000000, 15), (6000000,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_by = 2\n",
    "N_train = 1000000\n",
    "N_test = 6000000\n",
    "\n",
    "start_at = N_original - N_train - N_test\n",
    "split_at = start_at + N_train\n",
    "\n",
    "train_X = pd.DataFrame(train_data.iloc[start_at:split_at,:-1])\n",
    "train_Y = train_data.iloc[start_at:split_at,-1]\n",
    "test_X = pd.DataFrame(train_data.iloc[split_at:,:-1])\n",
    "test_Y = train_data.iloc[split_at:,-1]\n",
    "\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecad2386    685084\n",
       "92f5800b     79772\n",
       "e2fcccd2     30650\n",
       "9c13b419     13975\n",
       "03528b27     12199\n",
       "54c5d545     11801\n",
       "03a08c3f     10436\n",
       "febd1138      9582\n",
       "7358e05e      8331\n",
       "98fed791      8070\n",
       "e9739828      7568\n",
       "e2a1ca37      6472\n",
       "1dc72b4d      6178\n",
       "ce183bbd      5139\n",
       "f0d41ff1      4623\n",
       "51cedd4e      4606\n",
       "d36838b1      3910\n",
       "cf0327f9      3283\n",
       "d44c074c      3267\n",
       "de97da65      2981\n",
       "3c4b944d      2705\n",
       "f888bf4c      2310\n",
       "39947756      2040\n",
       "3e2bf98d      1909\n",
       "53de0284      1752\n",
       "75076517      1748\n",
       "a5184c22      1638\n",
       "c8e3e3c1      1603\n",
       "a37bf1e4      1546\n",
       "442cfede      1528\n",
       "             ...  \n",
       "abe9b3fe         1\n",
       "d65f9e62         1\n",
       "6bceaf84         1\n",
       "e9ec1d4d         1\n",
       "33954382         1\n",
       "444d80aa         1\n",
       "d84afa2e         1\n",
       "2ab2e91a         1\n",
       "d3010987         1\n",
       "4d15bfba         1\n",
       "5353a7c1         1\n",
       "dfa6b076         1\n",
       "d6038c05         1\n",
       "6837c486         1\n",
       "5e9ef6fe         1\n",
       "22018773         1\n",
       "9d9e17df         1\n",
       "8e4b0a7f         1\n",
       "16fd08fc         1\n",
       "448619a0         1\n",
       "dd1f7fd3         1\n",
       "baabf9fe         1\n",
       "6b18f740         1\n",
       "bd80e351         1\n",
       "e9a1cc91         1\n",
       "582036a1         1\n",
       "693ad3f5         1\n",
       "4d4a0c7c         1\n",
       "a8259bf6         1\n",
       "fd257cc8         1\n",
       "Name: card_id, Length: 1937, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['card_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "1. 0.6654 - 1 hot encoding of `product_category`\n",
    "2. 0.6264 - `hour` actualy decreases score. It will be removed for now, however it might be useful while combined with other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'50e219e0': (424776, 30890745), 'f028772b': (305212, 19154036), '3e814130': (89952, 4374429), '28905ebd': (168851, 10156417), 'f66779e6': (3483, 194148), '75fa27f6': (2870, 149373), 'c0dd3be3': (1772, 59456), '335d28a8': (2023, 114828), '72722551': (201, 11075), 'dedf689d': (61, 3438), '76b2941d': (115, 5993), '0569f928': (337, 19204), '42a36e14': (119, 5762), '5378d028': (23, 1817), '9ccfa2ea': (19, 1159), '8fd0aea4': (13, 778), 'bcf865d9': (54, 3294), 'a818d37a': (63, 5075), '70fb0e29': (56, 1869)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1000000, 14), (6000000, 14))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_treated = pipeline_full.fit_transform(train_X)\n",
    "test_X_treated = pipeline_full.transform(test_X)\n",
    "\n",
    "train_X_treated.shape, test_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263779372728707"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_X_treated, train_Y)\n",
    "test_pred_prob = model.predict_proba(test_X_treated)[:,1]\n",
    "\n",
    "roc_auc_score(test_Y, test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32369524, 15), (32369524,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X = train_data.iloc[:,:-1]\n",
    "train_data_Y = train_data.iloc[:,-1]\n",
    "train_data_X.shape, train_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32369524, 15)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_treated = pipeline_full.fit_transform(train_data_X)\n",
    "train_data_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_treated = pipeline_full.transform(submit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_data_X_treated, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(submit_data_treated)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isfraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32263877</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32263886</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32263890</td>\n",
       "      <td>0.319438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32263895</td>\n",
       "      <td>0.319438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32263896</td>\n",
       "      <td>0.034431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   isfraud\n",
       "0  32263877  0.018971\n",
       "1  32263886  0.000000\n",
       "2  32263890  0.319438\n",
       "3  32263895  0.319438\n",
       "4  32263896  0.034431"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = submit_data['id']\n",
    "submission['isfraud'] = pred_prob\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = 'data/submit.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch_the_fraudster3",
   "language": "python",
   "name": "catch_the_fraudster3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
