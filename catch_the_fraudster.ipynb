{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'timestamp',\n",
       "  'product_id',\n",
       "  'product_department',\n",
       "  'product_category',\n",
       "  'card_id',\n",
       "  'user_id',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'amount',\n",
       "  'isfraud'],\n",
       " 32369524)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_v2.csv')\n",
    "columns = list(train_data)\n",
    "N_original, M_original = train_data.shape\n",
    "columns, N_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "* With trees, normalizing features is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from include.DatetimeFromTimestamp import DatetimeFromTimestamp\n",
    "#from include.HourOfDay import HourOfDay\n",
    "#from include.DataFrameDropper import DataFrameDropper\n",
    "from include.DataFrameSelector import DataFrameSelector\n",
    "from include.FilterNMostCommon import FilterNMostCommon\n",
    "from include.UserEvaluator import UserEvaluator\n",
    "\n",
    "#columns_to_drop = ['id', 'timestamp', 'product_id', 'product_department', 'product_category', 'card_id', 'user_id']\n",
    "columns_to_use = ['C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'amount', 'daily_transactions_ratio', 'amount_transactions_ratio']\n",
    "#the hot encoded attributes are also used\n",
    "pipeline_normal = Pipeline([\n",
    "    #('hour_creator', HourOfDay()),\n",
    "    ('datetime_creator', DatetimeFromTimestamp()),\n",
    "    ('user_evaluator', UserEvaluator()),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=columns_to_use)),\n",
    "])\n",
    "\n",
    "pipeline_1hot = Pipeline([\n",
    "    ('dataframe_selector', DataFrameSelector(['product_category'])),\n",
    "    ('filter_n_most_common', FilterNMostCommon(N=5, attribute_name='product_category', minRelFreq=0.05)),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "pipeline_full = FeatureUnion(transformer_list=[\n",
    "    ('pipeline_normal', pipeline_normal),\n",
    "    ('pipeline_1hot', pipeline_1hot),\n",
    "])\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "* Normally I would use random sampling, stratified by an attribute of major relevance, however, in this case the test data that was given follows the train data in time. Therefore, in order to do local testing my first guess would be that it is better to remake that scenario and sample the data by simply splitting it sorted as it is, by time.\n",
    "* Cross validation is not necessary given that we have a test set big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15), (1000000,), (6000000, 15), (6000000,))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_by = 2\n",
    "N_train = 1000000\n",
    "N_test = 6000000\n",
    "\n",
    "start_at = N_original - N_train - N_test\n",
    "split_at = start_at + N_train\n",
    "\n",
    "train_X = pd.DataFrame(train_data.iloc[start_at:split_at,:-1])\n",
    "train_Y = train_data.iloc[start_at:split_at,-1]\n",
    "test_X = pd.DataFrame(train_data.iloc[split_at:,:-1])\n",
    "test_Y = train_data.iloc[split_at:,-1]\n",
    "\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "1. 0.6654 - 1 hot encoding of `product_category`\n",
    "2. 0.6264 - `hour` actualy decreases score. It will be removed for now, however it might be useful while combined with other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15), (6000000, 15))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_treated = pipeline_full.fit_transform(train_X)\n",
    "test_X_treated = pipeline_full.transform(test_X)\n",
    "\n",
    "train_X_treated.shape, test_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5858859085912868"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_X_treated, train_Y)\n",
    "test_pred_prob = model.predict_proba(test_X_treated)[:,1]\n",
    "\n",
    "roc_auc_score(test_Y, test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32369524, 15), (32369524,))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X = train_data.iloc[:,:-1]\n",
    "train_data_Y = train_data.iloc[:,-1]\n",
    "train_data_X.shape, train_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32369524, 15)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_treated = pipeline_full.fit_transform(train_data_X)\n",
    "train_data_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_treated = pipeline_full.transform(submit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_data_X_treated[18000000:,:], train_data_Y[18000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(submit_data_treated)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isfraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32263877</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32263886</td>\n",
       "      <td>0.053406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32263890</td>\n",
       "      <td>0.309616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32263895</td>\n",
       "      <td>0.309616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32263896</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   isfraud\n",
       "0  32263877  0.018000\n",
       "1  32263886  0.053406\n",
       "2  32263890  0.309616\n",
       "3  32263895  0.309616\n",
       "4  32263896  0.500000"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = submit_data['id']\n",
    "submission['isfraud'] = pred_prob\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = 'data/submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch_the_fraudster3",
   "language": "python",
   "name": "catch_the_fraudster3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
