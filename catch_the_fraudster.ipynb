{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['id',\n",
       "  'timestamp',\n",
       "  'product_id',\n",
       "  'product_department',\n",
       "  'product_category',\n",
       "  'card_id',\n",
       "  'user_id',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'amount',\n",
       "  'isfraud'],\n",
       " 32369524)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_v2.csv')\n",
    "columns = list(train_data)\n",
    "N_original, M_original = train_data.shape\n",
    "columns, N_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline\n",
    "* With trees, normalizing features is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from include.DatetimeFromTimestamp import DatetimeFromTimestamp\n",
    "#from include.HourOfDay import HourOfDay\n",
    "#from include.DataFrameDropper import DataFrameDropper\n",
    "from include.DataFrameSelector import DataFrameSelector\n",
    "from include.FilterNMostCommon import FilterNMostCommon\n",
    "from include.UserEvaluator import UserEvaluator\n",
    "\n",
    "#columns_to_drop = ['id', 'timestamp', 'product_id', 'product_department', 'product_category', 'card_id', 'user_id']\n",
    "columns_to_use = ['C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'amount'] #the hot encoded attributes are also used\n",
    "pipeline_normal = Pipeline([\n",
    "    #('hour_creator', HourOfDay()),\n",
    "    ('datetime_creator', DatetimeFromTimestamp()),\n",
    "    ('user_evaluator', UserEvaluator(col_names=list(train_data)[:-1] + ['datetime'])),\n",
    "    ('dataframe_selector', DataFrameSelector(attribute_names=columns_to_use)),\n",
    "])\n",
    "\n",
    "pipeline_1hot = Pipeline([\n",
    "    ('dataframe_selector', DataFrameSelector(['product_category'])),\n",
    "    ('filter_n_most_common', FilterNMostCommon(N=5, attribute_name='product_category')),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse = False))\n",
    "])\n",
    "\n",
    "pipeline_full = FeatureUnion(transformer_list=[\n",
    "    ('pipeline_normal', pipeline_normal),\n",
    "    ('pipeline_1hot', pipeline_1hot),\n",
    "])\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "* Normally I would use random sampling, stratified by an attribute of major relevance, however, in this case the test data that was given follows the train data in time. Therefore, in order to do local testing my first guess would be that it is better to remake that scenario and sample the data by simply splitting it sorted as it is, by time.\n",
    "* Cross validation is not necessary given that we have a test set big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 15), (1000000,), (6000000, 15), (6000000,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_by = 2\n",
    "N_train = 1000000\n",
    "N_test = 6000000\n",
    "\n",
    "start_at = N_original - N_train - N_test\n",
    "split_at = start_at + N_train\n",
    "\n",
    "train_X = pd.DataFrame(train_data.iloc[start_at:split_at,:-1])\n",
    "train_Y = train_data.iloc[start_at:split_at,-1]\n",
    "test_X = pd.DataFrame(train_data.iloc[split_at:,:-1])\n",
    "test_Y = train_data.iloc[split_at:,-1]\n",
    "\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "1. 0.6654 - 1 hot encoding of `product_category`\n",
    "2. 0.6264 - `hour` actualy decreases score. It will be removed for now, however it might be useful while combined with other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a99f214a    780220\n",
       "73b81e30       563\n",
       "cafca232       316\n",
       "f01ffaa6       316\n",
       "6d6314dc       313\n",
       "afeffc18       311\n",
       "c357dbff       297\n",
       "907e894c       270\n",
       "eec6d022       244\n",
       "8e1fb6c6       199\n",
       "936e92fb       148\n",
       "6d144653       138\n",
       "987552d1       130\n",
       "91436dab       116\n",
       "b09da1c4       111\n",
       "d857ffbb       109\n",
       "754f30e7       107\n",
       "ba3bf9e8       105\n",
       "f58a1c3b        95\n",
       "db99ea17        92\n",
       "41cfe06b        91\n",
       "3b34164a        89\n",
       "a4eb98c9        86\n",
       "56b07489        82\n",
       "ad2af41a        80\n",
       "53c3ad4d        78\n",
       "03559b29        77\n",
       "98326b84        75\n",
       "6b5b2eea        74\n",
       "8ed6e9a8        69\n",
       "             ...  \n",
       "972215d4         1\n",
       "39f8cf5e         1\n",
       "b5ed975d         1\n",
       "39ba8327         1\n",
       "dbbda7c2         1\n",
       "63b9a766         1\n",
       "7c54a420         1\n",
       "ecf343eb         1\n",
       "fbe378c9         1\n",
       "a3c8daee         1\n",
       "f140f050         1\n",
       "2956813a         1\n",
       "f7dda743         1\n",
       "7f864095         1\n",
       "3d66433e         1\n",
       "0be5d4ba         1\n",
       "fc227582         1\n",
       "875710b4         1\n",
       "40cdcb33         1\n",
       "bdb5032e         1\n",
       "101daa91         1\n",
       "a5f9896c         1\n",
       "f2e8a485         1\n",
       "717cec66         1\n",
       "3ee2ab16         1\n",
       "0ba80ef4         1\n",
       "c92ae8c7         1\n",
       "a30c5307         1\n",
       "432cca59         1\n",
       "10b28f3a         1\n",
       "Name: user_id, Length: 111316, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{25389332: (Timestamp('2014-10-27 12:28:05.439000'), 191.77), 25404001: (Timestamp('2014-10-27 12:01:42.091000'), 191.77), 25414517: (Timestamp('2014-10-27 12:11:44.100000'), 191.77), 25426667: (Timestamp('2014-10-27 12:00:38.267000'), 191.77), 25439461: (Timestamp('2014-10-27 12:22:28.310000'), 191.77), 25448002: (Timestamp('2014-10-27 12:54:05.069000'), 191.77), 25451177: (Timestamp('2014-10-27 12:43:55.481000'), 191.77), 25454799: (Timestamp('2014-10-27 12:55:30.932000'), 191.77), 25467938: (Timestamp('2014-10-27 12:10:57.018000'), 191.77), 25470944: (Timestamp('2014-10-27 12:05:38.448000'), 191.77), 25473017: (Timestamp('2014-10-27 12:05:33.017000'), 191.77), 25474884: (Timestamp('2014-10-27 12:13:14.273000'), 191.77), 25475026: (Timestamp('2014-10-27 12:55:30.220000'), 191.77), 25487159: (Timestamp('2014-10-27 12:01:25.663000'), 191.77), 25503259: (Timestamp('2014-10-27 12:54:16.285000'), 191.77), 25507217: (Timestamp('2014-10-27 12:22:14.150000'), 191.77), 25520726: (Timestamp('2014-10-27 12:16:09.238000'), 191.77), 25523816: (Timestamp('2014-10-27 12:21:28.015000'), 191.77), 25524330: (Timestamp('2014-10-27 12:28:40.585000'), 191.77), 25530876: (Timestamp('2014-10-27 12:05:51.993000'), 191.77), 25534310: (Timestamp('2014-10-27 12:50:00.571000'), 191.77), 25534618: (Timestamp('2014-10-27 12:55:41.745000'), 191.77), 25541743: (Timestamp('2014-10-27 12:02:41.804000'), 191.77), 25555310: (Timestamp('2014-10-27 13:13:16.593000'), 191.77), 25575597: (Timestamp('2014-10-27 13:00:22.661000'), 191.77), 25586077: (Timestamp('2014-10-27 13:58:49.211000'), 191.77), 25589280: (Timestamp('2014-10-27 13:44:48.726000'), 191.77), 25595733: (Timestamp('2014-10-27 13:58:12.322000'), 191.77), 25650988: (Timestamp('2014-10-27 13:47:34.891000'), 191.77), 25668124: (Timestamp('2014-10-27 13:27:20.212000'), 191.77), 25671889: (Timestamp('2014-10-27 13:05:10.699000'), 191.77), 25678585: (Timestamp('2014-10-27 13:45:22.291000'), 191.77), 25700476: (Timestamp('2014-10-27 13:31:21.975000'), 191.77), 25706262: (Timestamp('2014-10-27 13:17:00.009000'), 191.77), 25710082: (Timestamp('2014-10-27 13:18:32.831000'), 191.77), 25719865: (Timestamp('2014-10-27 13:17:04.721000'), 191.77), 25722054: (Timestamp('2014-10-27 13:13:58.730000'), 191.77), 25725778: (Timestamp('2014-10-27 14:38:00.674000'), 191.77), 25739544: (Timestamp('2014-10-27 14:40:04.217000'), 191.77), 25770672: (Timestamp('2014-10-27 14:58:27.023000'), 191.77), 25785566: (Timestamp('2014-10-27 14:32:04.305000'), 191.77), 25787697: (Timestamp('2014-10-27 14:14:36.289000'), 191.77), 25802130: (Timestamp('2014-10-27 14:36:38.414000'), 191.77), 25871214: (Timestamp('2014-10-27 15:01:19.772000'), 191.77), 25882094: (Timestamp('2014-10-27 15:53:05.583000'), 191.77), 25898814: (Timestamp('2014-10-27 15:10:51.313000'), 191.77), 25920011: (Timestamp('2014-10-27 15:55:54.332000'), 191.77), 25953146: (Timestamp('2014-10-27 16:04:07.639000'), 191.77), 25978942: (Timestamp('2014-10-27 16:45:13.410000'), 191.77), 26002264: (Timestamp('2014-10-27 16:26:49.289000'), 191.77), 26007694: (Timestamp('2014-10-27 16:01:30.589000'), 191.77), 26024723: (Timestamp('2014-10-27 16:28:42.052000'), 191.77), 26080466: (Timestamp('2014-10-27 16:16:47.626000'), 191.77), 26127864: (Timestamp('2014-10-27 17:40:58.506000'), 191.77), 26138473: (Timestamp('2014-10-27 17:29:08.109000'), 191.77), 26147757: (Timestamp('2014-10-27 17:06:11.885000'), 191.77), 26153381: (Timestamp('2014-10-27 17:55:46.962000'), 191.77), 26175902: (Timestamp('2014-10-27 17:31:35.218000'), 191.77), 26189011: (Timestamp('2014-10-27 17:55:02.707000'), 191.77), 26196631: (Timestamp('2014-10-27 17:24:26.897000'), 191.77), 26215527: (Timestamp('2014-10-27 17:37:12.779000'), 191.77), 26227451: (Timestamp('2014-10-27 17:17:42.801000'), 191.77), 26250610: (Timestamp('2014-10-27 17:35:27.950000'), 191.77), 26253492: (Timestamp('2014-10-27 17:26:46.554000'), 191.77), 26263550: (Timestamp('2014-10-27 17:19:47.819000'), 191.77), 26269754: (Timestamp('2014-10-27 17:23:11.746000'), 191.77), 26330978: (Timestamp('2014-10-27 17:06:36.141000'), 191.77), 26333408: (Timestamp('2014-10-27 17:51:34.669000'), 191.77), 26359945: (Timestamp('2014-10-27 18:31:51.274000'), 191.77)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1000000, 14), (6000000, 14))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_treated = pipeline_full.fit_transform(train_X)\n",
    "test_X_treated = pipeline_full.transform(test_X)\n",
    "\n",
    "train_X_treated.shape, test_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "current_model = DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263779372728707"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_X_treated, train_Y)\n",
    "test_pred_prob = model.predict_proba(test_X_treated)[:,1]\n",
    "\n",
    "roc_auc_score(test_Y, test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = pd.read_csv('data/test_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train and submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32369524, 15), (32369524,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X = train_data.iloc[:,:-1]\n",
    "train_data_Y = train_data.iloc[:,-1]\n",
    "train_data_X.shape, train_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32369524, 15)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X_treated = pipeline_full.fit_transform(train_data_X)\n",
    "train_data_X_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data_treated = pipeline_full.transform(submit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = current_model(random_state=random_seed)\n",
    "model.fit(train_data_X_treated, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(submit_data_treated)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>isfraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32263877</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32263886</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32263890</td>\n",
       "      <td>0.319438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32263895</td>\n",
       "      <td>0.319438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32263896</td>\n",
       "      <td>0.034431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   isfraud\n",
       "0  32263877  0.018971\n",
       "1  32263886  0.000000\n",
       "2  32263890  0.319438\n",
       "3  32263895  0.319438\n",
       "4  32263896  0.034431"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = submit_data['id']\n",
    "submission['isfraud'] = pred_prob\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf = 'data/submit.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch_the_fraudster3",
   "language": "python",
   "name": "catch_the_fraudster3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
